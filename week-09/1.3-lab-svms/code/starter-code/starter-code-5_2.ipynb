{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will explore several datasets with SVMs. The assets folder contains several datasets (in order of complexity):\n",
    "\n",
    "1. Breast cancer\n",
    "- Spambase\n",
    "- Car evaluation\n",
    "- Mushroom\n",
    "\n",
    "For each of these a `.names` file is provided with details on the origin of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Breast Cancer\n",
    "\n",
    "\n",
    "\n",
    "## 1.a: Load the Data\n",
    "Use `pandas.read_csv` to load the data and assess the following:\n",
    "- Are there any missing values? (how are they encoded? do we impute them?)\n",
    "- Are the features categorical or numerical?\n",
    "- Are the values normalized?\n",
    "- How many classes are there in the target?\n",
    "\n",
    "Perform what's necessary to get to a point where you have a feature matrix `X` and a target vector `y`, both with only numerical entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcancer=pd.read_csv('/Users/samanthafalk/class-GA/week-09/1.3-lab-svms/assets/datasets/breast_cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      "Sample_code_number             699 non-null int64\n",
      "Clump_Thickness                699 non-null int64\n",
      "Uniformity_of_Cell_Size        699 non-null int64\n",
      "Uniformity_of_Cell_Shape       699 non-null int64\n",
      "Marginal_Adhesion              699 non-null int64\n",
      "Single_Epithelial_Cell_Size    699 non-null int64\n",
      "Bare_Nuclei                    699 non-null object\n",
      "Bland_Chromatin                699 non-null int64\n",
      "Normal_Nucleoli                699 non-null int64\n",
      "Mitoses                        699 non-null int64\n",
      "Class                          699 non-null int64\n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.1+ KB\n"
     ]
    }
   ],
   "source": [
    "bcancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '2', '4', '3', '9', '7', '?', '5', '8', '6'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcancer['Bare_Nuclei'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcancer['Bare_Nuclei']=[np.nan if x=='?' else int(x) for x in bcancer['Bare_Nuclei']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcancer.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    444\n",
       "4    239\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcancer['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcancer['Class']=[0 if x==2 else 1 for x in bcancer['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=bcancer.iloc[:,:-1]\n",
    "y=bcancer.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Scaled_X=preprocessing.StandardScaler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6959247648902821"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "444/638."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Baseline is 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b: Model Building\n",
    "\n",
    "- What's the baseline for the accuracy?\n",
    "- Initialize and train a linear svm. What's the average accuracy score with a 3-fold cross validation?\n",
    "- Repeat using an rbf classifier. Compare the scores. Which one is better?\n",
    "- Are your features normalized? if not, try normalizing and repeat the test. Does the score improve?\n",
    "- What's the best model?\n",
    "- Print a confusion matrix and classification report for your best model using:\n",
    "        train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n",
    "\n",
    "**Check** to decide which model is best, look at the average cross validation score. Are the scores significantly different from one another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf=SVC(kernel='linear')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** Are there more false positives or false negatives? Is this good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c: Feature Selection\n",
    "\n",
    "Use any of the strategies offered by `sklearn` to select the most important features.\n",
    "\n",
    "Repeat the cross validation with only those 5 features. Does the score change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d: Learning Curves\n",
    "\n",
    "Learning curves are useful to study the behavior of training and test errors as a function of the number of datapoints available.\n",
    "\n",
    "- Plot learning curves for train sizes between 10% and 100% (use StratifiedKFold with 5 folds as cross validation)\n",
    "- What can you say about the dataset? do you need more data or do you need a better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.e: Grid Ssearch\n",
    "\n",
    "Use the grid_search function to explore different kernels and values for the C parameter.\n",
    "\n",
    "- Can you improve on your best previous score?\n",
    "- Print the best parameters and the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Now that you've completed steps 1.a through 1.e it's time to tackle some harder datasets. But before we do that, let's encapsulate a few things into functions so that it's easier to repeat the analysis.\n",
    "\n",
    "## 2.a: Cross Validation\n",
    "Implement a function `do_cv(model, X, y, cv)` that does the following:\n",
    "- Calculates the cross validation scores\n",
    "- Prints the model\n",
    "- Prints and returns the mean and the standard deviation of the cross validation scores\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.b: Confusion Matrix and Classification report\n",
    "Implement a function `do_cm_cr(model, X, y, names)` that automates the following:\n",
    "- Split the data using `train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)`\n",
    "- Fit the model\n",
    "- Prints confusion matrix and classification report in a nice format\n",
    "\n",
    "**Hint:** names is the list of target classes\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.c: Learning Curves\n",
    "Implement a function `do_learning_curve(model, X, y, sizes)` that automates drawing the learning curves:\n",
    "- Allow for sizes input\n",
    "- Use 5-fold StratifiedKFold cross validation\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.d: Grid Search\n",
    "Implement a function `do_grid_search(model, parameters)` that automates the grid search by doing:\n",
    "- Calculate grid search\n",
    "- Print best parameters\n",
    "- Print best score\n",
    "- Return best estimator\n",
    "\n",
    "\n",
    "> Answer: see above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "Using the functions above, analyze the Spambase dataset.\n",
    "\n",
    "Notice that now you have many more features. Focus your attention on step C => feature selection\n",
    "\n",
    "- Load the data and get to X, y\n",
    "- Select the 15 best features\n",
    "- Perform grid search to determine best model\n",
    "- Display learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "Repeat steps 1.a - 1.e for the car dataset. Notice that now features are categorical, not numerical.\n",
    "- Find a suitable way to encode them\n",
    "- How does this change our modeling strategy?\n",
    "\n",
    "Also notice that the target variable `acceptability` has 4 classes. How do we encode them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "Repeat steps 1.a - 1.e for the mushroom dataset. Notice that now features are categorical, not numerical. This dataset is quite large.\n",
    "- How does this change our modeling strategy?\n",
    "- Can we use feature selection to improve this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
